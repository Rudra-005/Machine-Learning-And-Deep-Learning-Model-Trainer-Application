# ML/DL Training Platform

A scalable, production-ready web-based Machine Learning and Deep Learning training platform.

## Features

- **Data Upload & Exploration**: Upload CSV datasets with automatic data quality checks
- **Flexible Model Selection**: Choose from ML (Scikit-learn) or DL (TensorFlow/Keras) models
- **Hyperparameter Configuration**: Tune learning rate, epochs, batch size, and more
- **Automatic Preprocessing**: Missing value imputation, scaling, categorical encoding
- **Model Training**: Single and cross-validation training modes
- **Comprehensive Evaluation**: Classification and regression metrics
- **Visualization**: Confusion matrices, feature importance, residual plots
- **Model Persistence**: Save and load trained models
- **Session Management**: Track multiple training sessions

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Streamlit Frontend UI           ‚îÇ
‚îÇ  (Data Upload, Config, Training)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   FastAPI Backend (Optional)        ‚îÇ
‚îÇ  (API Routes, Session Management)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ                  ‚îÇ              ‚îÇ          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Preprocessing‚îÇ   ‚îÇModel    ‚îÇ   ‚îÇEval.  ‚îÇ   ‚îÇStorage ‚îÇ
‚îÇ & Features   ‚îÇ   ‚îÇTraining ‚îÇ   ‚îÇMetrics‚îÇ   ‚îÇRepos   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Folder Structure

```
ML_DL_Trainer/
‚îú‚îÄ‚îÄ app/                          # Frontend application
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # Streamlit entry point
‚îÇ   ‚îú‚îÄ‚îÄ config.py                 # Configuration
‚îÇ   ‚îî‚îÄ‚îÄ utils/                    # Utilities
‚îÇ       ‚îú‚îÄ‚îÄ file_handler.py
‚îÇ       ‚îú‚îÄ‚îÄ logger.py
‚îÇ       ‚îî‚îÄ‚îÄ validators.py
‚îú‚îÄ‚îÄ backend/                      # Backend services
‚îÇ   ‚îú‚îÄ‚îÄ session_manager.py        # Session management
‚îÇ   ‚îî‚îÄ‚îÄ task_queue.py             # Async task handling
‚îú‚îÄ‚îÄ core/                         # Core ML operations
‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.py           # Data preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineer.py       # Feature engineering
‚îÇ   ‚îî‚îÄ‚îÄ validator.py              # Data validation
‚îú‚îÄ‚îÄ models/                       # ML/DL models
‚îÇ   ‚îú‚îÄ‚îÄ model_factory.py          # Model creation
‚îÇ   ‚îú‚îÄ‚îÄ ml/                       # SKL models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classifier.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ regressor.py
‚îÇ   ‚îî‚îÄ‚îÄ dl/                       # TensorFlow models
‚îÇ       ‚îú‚îÄ‚îÄ cnn_models.py
‚îÇ       ‚îî‚îÄ‚îÄ rnn_models.py
‚îú‚îÄ‚îÄ evaluation/                   # Evaluation utilities
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                # Metrics calculation
‚îÇ   ‚îú‚îÄ‚îÄ visualizer.py             # Plotting utilities
‚îÇ   ‚îú‚îÄ‚îÄ reporter.py               # Report generation
‚îÇ   ‚îî‚îÄ‚îÄ cross_validator.py        # CV utilities
‚îú‚îÄ‚îÄ storage/                      # Data persistence
‚îÇ   ‚îú‚îÄ‚îÄ model_repository.py       # Model storage
‚îÇ   ‚îú‚îÄ‚îÄ result_repository.py      # Results storage
‚îÇ   ‚îî‚îÄ‚îÄ cache_manager.py          # Caching
‚îú‚îÄ‚îÄ data/                         # Data directories
‚îÇ   ‚îú‚îÄ‚îÄ uploads/                  # User uploaded files
‚îÇ   ‚îú‚îÄ‚îÄ preprocessed/             # Processed data
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # Trained models
‚îÇ   ‚îî‚îÄ‚îÄ results/                  # Experiment results
‚îú‚îÄ‚îÄ tests/                        # Unit tests
‚îú‚îÄ‚îÄ requirements.txt              # Dependencies
‚îî‚îÄ‚îÄ README.md                     # This file
```

## Installation

### Prerequisites
- Python 3.9 or higher
- pip or conda

### Setup

1. Clone the repository:
```bash
git clone https://github.com/yourusername/ML_DL_Trainer.git
cd ML_DL_Trainer
```

2. Create virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set environment variables:
```bash
# Create .env file
echo "DEBUG=False" > .env
echo "LOG_LEVEL=INFO" >> .env
```

## Usage

### Run Streamlit Application

```bash
streamlit run app/main.py
```

The application will open at `http://localhost:8501`

### Workflow

1. **Home Page**: Overview and getting started guide
2. **Data Upload**: Upload CSV file and explore data
3. **Training**: Select model, configure hyperparameters, and train
4. **Results**: View metrics, visualizations, and download model
5. **About**: Platform information

## Supported Models

### Machine Learning (Scikit-learn)

**Classification:**
- **Logistic Regression** - Fast, interpretable, baseline model
- **Random Forest** - Robust ensemble, handles non-linear relationships
- **Support Vector Machine (SVM)** - Excellent for high-dimensional data
- **Gradient Boosting** - Sequential ensemble learning with proven accuracy
- **XGBoost** *(Optional)* - Optimized gradient boosting, industry standard
- **LightGBM** *(Optional)* - Fast boosting with lower memory footprint

**Regression:**
- **Linear Regression** - Simple baseline
- **Random Forest** - Robust ensemble approach
- **Support Vector Regression (SVR)** - For non-linear problems
- **Gradient Boosting** - Sequential boosting for complex patterns
- **XGBoost** *(Optional)* - High-performance boosting
- **LightGBM** *(Optional)* - Memory-efficient boosting

### Deep Learning (TensorFlow/Keras)

- Sequential Neural Networks
- Convolutional Neural Networks (CNN)
- Recurrent Neural Networks (RNN/LSTM)

### Optional Libraries

| Library | Status | Installation |
|---------|--------|---------------|
| XGBoost | Optional | `pip install xgboost` |
| LightGBM | Optional | `pip install lightgbm` |
| SMOTE | Optional | `pip install imbalanced-learn` |

‚úÖ **Core functionality works without optional libraries** - graceful fallback if not installed

## Model Selection Guide

### When to Use Each Model

| Model | Best For | Pros | Cons |
|-------|----------|------|------|
| **Logistic Regression** | Baseline, interpretability | Fast, explainable | Limited for complex patterns |
| **Random Forest** | General-purpose | Robust, feature importance | Can overfit with defaults |
| **SVM** | High-dimensional data | Powerful, versatile | Slow on large datasets |
| **Gradient Boosting** | Kaggle competitions, production | High accuracy, handles imbalance | Slower training |
| **XGBoost** | Production ML, tabular data | Industry-standard, optimized | Requires tuning |
| **LightGBM** | Large datasets, fast iteration | Memory-efficient, rapid training | Fewer hyperparameters |
| **Neural Networks** | Complex patterns, images, sequences | Flexible, scalable | Needs more data, tuning |

### Quick Decision Tree

```
‚îå‚îÄ Small dataset (<10K rows)?          ‚Üí Random Forest
‚îú‚îÄ Structured/tabular data?           ‚Üí XGBoost or LightGBM
‚îú‚îÄ Need interpretability?             ‚Üí Logistic Regression
‚îú‚îÄ Imbalanced classification?         ‚Üí Gradient Boosting (with class weights)
‚îú‚îÄ High-dimensional (>1000 features)? ‚Üí SVM or Neural Network
‚îú‚îÄ Images/sequences?                  ‚Üí Neural Networks (CNN/RNN)
‚îî‚îÄ Unsure?                            ‚Üí Start with Random Forest
```

### Why These Models Were Added

**Gradient Boosting (Built-in)**
- ‚úÖ Scikit-learn native - no extra dependencies
- ‚úÖ Excellent imbalanced dataset support
- ‚úÖ Industry-proven accuracy
- ‚úÖ Reasonable training time for most datasets

**XGBoost (Optional)**
- ‚úÖ 10-20% accuracy improvement over standard GB
- ‚úÖ Industry standard in Kaggle competitions
- ‚úÖ Advanced regularization features
- ‚úÖ Handles missing values automatically
- ‚ö†Ô∏è Separate installation (faster iteration for users without it)

**LightGBM (Optional)**
- ‚úÖ 2-5x faster than XGBoost on large datasets
- ‚úÖ Lower memory requirements
- ‚úÖ Better with millions of rows
- ‚ö†Ô∏è Different hyperparameter meanings (separate installation)

### Factory Pattern for Easy Extension

The `ModelFactory` class enables effortless model addition:

```python
# Adding a new model is just 3 lines:
def build_my_model(**params):
    return MyModel(**params)

ModelFactory.register_model(
    'classification', 'my_model', build_my_model,
    defaults={'param1': value}
)
```

**Benefits:**
- ‚úÖ No UI changes needed - automatically appears in dropdown
- ‚úÖ No train.py or evaluate.py modifications
- ‚úÖ Hyperparameters configurable per-model
- ‚úÖ Graceful fallback if optional libraries missing

## Key Design Patterns

1. **Factory Pattern**: ModelFactory for flexible model creation
2. **Repository Pattern**: Model and result storage
3. **Pipeline Pattern**: Data preprocessing pipeline
4. **Observer Pattern**: Real-time training callbacks
5. **Session Pattern**: User session management

## API Endpoints (FastAPI)

Future endpoints for backend integration:

```
POST   /api/upload               - Upload dataset
POST   /api/train                - Start training
GET    /api/train/{session_id}   - Get training status
GET    /api/results/{session_id} - Get results
GET    /api/models               - List models
GET    /api/models/{model_id}    - Download model
```

## Configuration

Edit `app/config.py` to customize:

```python
MAX_FILE_SIZE = 500 * 1024 * 1024  # Max upload size
DEFAULT_TEST_SIZE = 0.2             # Train-test split
DEFAULT_CV_FOLDS = 5                # Cross-validation folds
DEFAULT_EPOCHS = 50                 # DL epochs
DEFAULT_BATCH_SIZE = 32             # DL batch size
```

## Testing

Run unit tests:

```bash
pytest tests/ -v
```

## Production Deployment

### Docker

```bash
docker-compose up -d
```

### Cloud Deployment

**AWS:**
- Use EC2 for app hosting
- S3 for model/data storage
- RDS for metadata database

**Google Cloud:**
- Cloud Run for serverless deployment
- Cloud Storage for models
- Cloud SQL for database

**Azure:**
- App Service for hosting
- Blob Storage for models
- SQL Database for metadata

## Scalability Path

| Component | Dev | Prod |
|-----------|-----|------|
| Frontend | Streamlit | Streamlit + Load Balancer |
| Backend | Single thread | Celery + Redis |
| Database | SQLite | PostgreSQL |
| Storage | Local FS | S3/GCS |
| Caching | In-memory | Redis |
| Monitoring | Logs | ELK Stack |

## Security Considerations

- ‚úÖ Input validation for file uploads
- ‚úÖ CSRF protection
- ‚úÖ Secure model serialization
- ‚úÖ Environment-based configuration
- ‚úÖ Logging and audit trails
- ‚ö†Ô∏è TODO: User authentication
- ‚ö†Ô∏è TODO: Role-based access control

## Performance Tips

1. Use stratified split for imbalanced datasets
2. Enable cross-validation for robust evaluation
3. Use feature scaling for distance-based algorithms
4. Cache preprocessed data for large datasets
5. Use GPU acceleration for DL models

## Troubleshooting

**Issue**: Memory error with large datasets
- **Solution**: Increase system RAM or use data streaming

**Issue**: Slow training
- **Solution**: Use smaller batch size or fewer features

**Issue**: Import errors
- **Solution**: Verify all dependencies: `pip install -r requirements.txt`

## Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Create Pull Request

## License

MIT License - see LICENSE file

## Support

- üìß Email: support@example.com
- üí¨ Issues: GitHub Issues
- üìñ Documentation: [Wiki](https://github.com/yourusername/ML_DL_Trainer/wiki)

## Roadmap

- [ ] User authentication
- [ ] Model versioning
- [ ] Hyperparameter optimization
- [ ] AutoML integration
- [ ] Model explainability (SHAP, LIME)
- [ ] Real-time collaboration
- [ ] Mobile app
- [ ] Advanced visualizations

---

**Made with ‚ù§Ô∏è for the ML/DL community**
